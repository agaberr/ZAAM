{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def swap_entities(example):\n",
    "    text = example['text']\n",
    "    candidates = example['candidates'].copy()\n",
    "    correct_idx = example['correct_candidate_idx']\n",
    "    \n",
    "    # Create pool of replacement entities by gender/type\n",
    "    male_names = [\"John\", \"Michael\", \"David\", \"Robert\", \"James\", \"Thomas\", \"William\", \"Richard\",\"Mohamed\",\"Ahmed\",\"Omar\",\"Osama\",\"Amr\",\"Magdy\",\"Waleed\",\"Ayman\"]\n",
    "    female_names = [\"Mary\", \"Jennifer\", \"Linda\", \"Patricia\", \"Elizabeth\", \"Susan\", \"Jessica\", \"Sarah\"]\n",
    "    organizations = [\"Microsoft\", \"Google\", \"Amazon\", \"Apple\", \"IBM\", \"Tesla\", \"Facebook\", \"Twitter\"]\n",
    "    locations = [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\", \"Sydney\", \"Rome\", \"Moscow\"]\n",
    "    \n",
    "    # Determine entity type for each candidate\n",
    "    entity_types = []\n",
    "    for candidate in candidates:\n",
    "        if candidate in male_names:\n",
    "            entity_types.append(\"male\")\n",
    "        elif candidate in female_names:\n",
    "            entity_types.append(\"female\")\n",
    "        elif candidate in organizations:\n",
    "            entity_types.append(\"organization\")\n",
    "        elif candidate in locations:\n",
    "            entity_types.append(\"location\")\n",
    "        else:\n",
    "            entity_types.append(\"unknown\")\n",
    "    \n",
    "    # Create substitution map\n",
    "    substitutions = {}\n",
    "    for i, candidate in enumerate(candidates):\n",
    "        entity_type = entity_types[i]\n",
    "        if entity_type == \"male\":\n",
    "            replacement = random.choice([n for n in male_names if n != candidate])\n",
    "        elif entity_type == \"female\":\n",
    "            replacement = random.choice([n for n in female_names if n != candidate])\n",
    "        elif entity_type == \"organization\":\n",
    "            replacement = random.choice([o for o in organizations if o != candidate])\n",
    "        elif entity_type == \"location\":\n",
    "            replacement = random.choice([l for l in locations if l != candidate])\n",
    "        else:\n",
    "            replacement = candidate  # No replacement for unknown types\n",
    "        \n",
    "        substitutions[candidate] = replacement\n",
    "    \n",
    "    # Apply substitutions\n",
    "    new_text = text\n",
    "    new_candidates = []\n",
    "    for old_entity, new_entity in substitutions.items():\n",
    "        new_text = new_text.replace(old_entity, new_entity)\n",
    "        new_candidates.append(new_entity)\n",
    "    \n",
    "    # Create augmented example\n",
    "    augmented = example.copy()\n",
    "    augmented['text'] = new_text\n",
    "    augmented['candidates'] = new_candidates\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vary_pronouns(example):\n",
    "    text = example['text']\n",
    "    pronoun = example['pronoun']\n",
    "    pronoun_position = example['pronoun_position']\n",
    "    \n",
    "    # Define pronoun mapping groups\n",
    "    subject_pronouns = {\"he\": [\"he\", \"they\"], \"she\": [\"she\", \"they\"], \"they\": [\"they\", \"he\", \"she\"]}\n",
    "    object_pronouns = {\"him\": [\"him\", \"them\"], \"her\": [\"her\", \"them\"], \"them\": [\"them\", \"him\", \"her\"]}\n",
    "    possessive_pronouns = {\"his\": [\"his\", \"their\"], \"her\": [\"her\", \"their\"], \"their\": [\"their\", \"his\", \"her\"]}\n",
    "    \n",
    "    # Determine pronoun type\n",
    "    pronoun_lower = pronoun.lower()\n",
    "    if pronoun_lower in subject_pronouns:\n",
    "        alternatives = subject_pronouns[pronoun_lower]\n",
    "    elif pronoun_lower in object_pronouns:\n",
    "        alternatives = object_pronouns[pronoun_lower]\n",
    "    elif pronoun_lower in possessive_pronouns:\n",
    "        alternatives = possessive_pronouns[pronoun_lower]\n",
    "    else:\n",
    "        return [example]  # No variations if pronoun type not recognized\n",
    "    \n",
    "    # Create variations\n",
    "    variations = []\n",
    "    for alt_pronoun in alternatives:\n",
    "        if alt_pronoun == pronoun_lower:\n",
    "            continue\n",
    "            \n",
    "        # Match case\n",
    "        if pronoun[0].isupper():\n",
    "            alt_pronoun = alt_pronoun.capitalize()\n",
    "            \n",
    "        # Replace pronoun in text\n",
    "        new_text = text[:pronoun_position] + alt_pronoun + text[pronoun_position + len(pronoun):]\n",
    "        \n",
    "        # Create new example\n",
    "        new_example = example.copy()\n",
    "        new_example['text'] = new_text\n",
    "        new_example['pronoun'] = alt_pronoun\n",
    "        variations.append(new_example)\n",
    "        \n",
    "    return variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def modify_sentence_structure(example):\n",
    "    text = example['text']\n",
    "    pronoun = example['pronoun']\n",
    "    candidates = example['candidates']\n",
    "    correct_idx = example['correct_candidate_idx']\n",
    "    \n",
    "    # Split into sentences\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    if len(sentences) < 2:\n",
    "        return [example]  # Can't reorder if only one sentence\n",
    "    \n",
    "    # Create variations by reordering sentences\n",
    "    variations = []\n",
    "    \n",
    "    # Simple sentence order reversal\n",
    "    if len(sentences) == 2:\n",
    "        new_text = sentences[1] + \" \" + sentences[0]\n",
    "        \n",
    "        # Need to recalculate pronoun position\n",
    "        original_pronoun_pos = example['pronoun_position']\n",
    "        if original_pronoun_pos < len(sentences[0]):\n",
    "            # Pronoun was in first sentence, now it's after second sentence\n",
    "            new_pronoun_pos = len(sentences[1]) + 1 + original_pronoun_pos\n",
    "        else:\n",
    "            # Pronoun was in second sentence, now it's at the beginning\n",
    "            new_pronoun_pos = original_pronoun_pos - len(sentences[0]) - 1\n",
    "        \n",
    "        new_example = example.copy()\n",
    "        new_example['text'] = new_text\n",
    "        new_example['pronoun_position'] = new_pronoun_pos\n",
    "        variations.append(new_example)\n",
    "    \n",
    "    # For longer texts, create more complex variations\n",
    "    # (This would require more sophisticated NLP to ensure coreference is preserved)\n",
    "    \n",
    "    return variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distractors(example):\n",
    "    text = example['text']\n",
    "    pronoun = example['pronoun']\n",
    "    candidates = example['candidates'].copy()\n",
    "    correct_idx = example['correct_candidate_idx']\n",
    "    \n",
    "    # Determine pronoun gender/type\n",
    "    pronoun_lower = pronoun.lower()\n",
    "    is_male = pronoun_lower in [\"he\", \"him\", \"his\"]\n",
    "    is_female = pronoun_lower in [\"she\", \"her\", \"hers\"]\n",
    "    is_plural = pronoun_lower in [\"they\", \"them\", \"their\"]\n",
    "    is_neutral = pronoun_lower in [\"it\", \"its\"]\n",
    "    \n",
    "    # Choose appropriate distractors\n",
    "    distractors = []\n",
    "    if is_male:\n",
    "        distractors = [\"James\", \"Robert\", \"Michael\", \"William\", \"David\"]\n",
    "    elif is_female:\n",
    "        distractors = [\"Mary\", \"Patricia\", \"Jennifer\", \"Linda\", \"Elizabeth\"]\n",
    "    elif is_plural:\n",
    "        distractors = [\"The team\", \"The group\", \"The committee\", \"The family\", \"The couple\"]\n",
    "    elif is_neutral:\n",
    "        distractors = [\"The car\", \"The book\", \"The phone\", \"The computer\", \"The house\"]\n",
    "    \n",
    "    # If no appropriate distractors were found, return the original example\n",
    "    if not distractors:\n",
    "        return example\n",
    "    \n",
    "    # Add 1-2 distractors to the text, but no more than available\n",
    "    num_distractors = min(random.randint(1, 2), len(distractors))\n",
    "    selected_distractors = random.sample(distractors, num_distractors)\n",
    "    \n",
    "    # Rest of the function remains the same...\n",
    "    \n",
    "    # Find appropriate places to insert distractors\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    if len(sentences) >= 2:\n",
    "        # Insert distractors in a way that doesn't change correct resolution\n",
    "        augmented_sentences = sentences.copy()\n",
    "        \n",
    "        for distractor in selected_distractors:\n",
    "            insert_idx = random.randint(0, len(augmented_sentences) - 1)\n",
    "            \n",
    "            # Create a distractor phrase\n",
    "            actions = [\"said\", \"mentioned\", \"noted\", \"explained\", \"suggested\"]\n",
    "            action = random.choice(actions)\n",
    "            distractor_phrase = f\" {distractor} {action} something important. \"\n",
    "            \n",
    "            # Insert at beginning or end of the selected sentence\n",
    "            if random.choice([True, False]):\n",
    "                augmented_sentences[insert_idx] = distractor_phrase + augmented_sentences[insert_idx]\n",
    "            else:\n",
    "                augmented_sentences[insert_idx] = augmented_sentences[insert_idx] + distractor_phrase\n",
    "        \n",
    "        new_text = \" \".join(augmented_sentences)\n",
    "        \n",
    "        # Add distractors to candidates list\n",
    "        new_candidates = candidates + selected_distractors\n",
    "        \n",
    "        # Create new example\n",
    "        new_example = example.copy()\n",
    "        new_example['text'] = new_text\n",
    "        new_example['candidates'] = new_candidates\n",
    "        \n",
    "        # Adjust correct_candidate_idx if needed\n",
    "        new_example['correct_candidate_idx'] = correct_idx\n",
    "        \n",
    "        return new_example\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cross_domain(examples, domain_type):\n",
    "\n",
    "    # Domain-specific patterns and vocabulary\n",
    "    domains = {\n",
    "        \"news\": {\n",
    "            \"patterns\": [\n",
    "                \"{candidate} stated that {rest}\",\n",
    "                \"According to {candidate}, {rest}\",\n",
    "                \"Sources close to {candidate} revealed that {rest}\"\n",
    "            ],\n",
    "            \"verbs\": [\"reported\", \"announced\", \"confirmed\", \"stated\", \"claimed\"],\n",
    "        },\n",
    "        \"academic\": {\n",
    "            \"patterns\": [\n",
    "                \"{candidate}'s research suggests that {rest}\",\n",
    "                \"In the study conducted by {candidate}, {rest}\",\n",
    "                \"As {candidate} theorized, {rest}\"\n",
    "            ],\n",
    "            \"verbs\": [\"analyzed\", \"hypothesized\", \"concluded\", \"investigated\", \"examined\"],\n",
    "        },\n",
    "        \"fiction\": {\n",
    "            \"patterns\": [\n",
    "                \"{candidate} gazed out the window as {rest}\",\n",
    "                \"With a sigh, {candidate} realized that {rest}\",\n",
    "                \"Walking slowly, {candidate} thought about how {rest}\"\n",
    "            ],\n",
    "            \"verbs\": [\"whispered\", \"thought\", \"wondered\", \"felt\", \"dreamed\"],\n",
    "        },\n",
    "        \"conversation\": {\n",
    "            \"patterns\": [\n",
    "                \"{candidate} was like, '{rest}'\",\n",
    "                \"'Hey,' {candidate} said, '{rest}'\",\n",
    "                \"{candidate} told me that {rest}\"\n",
    "            ],\n",
    "            \"verbs\": [\"said\", \"mentioned\", \"talked about\", \"brought up\", \"discussed\"],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if domain_type not in domains:\n",
    "        return examples\n",
    "    \n",
    "    domain_data = domains[domain_type]\n",
    "    patterns = domain_data[\"patterns\"]\n",
    "    verbs = domain_data[\"verbs\"]\n",
    "    \n",
    "    domain_examples = []\n",
    "    \n",
    "    for example in examples:\n",
    "        candidates = example['candidates']\n",
    "        correct_idx = example['correct_candidate_idx']\n",
    "        correct_candidate = candidates[correct_idx]\n",
    "        \n",
    "        # Choose a random pattern\n",
    "        pattern = random.choice(patterns)\n",
    "        verb = random.choice(verbs)\n",
    "        \n",
    "        # Create a simple sentence with the pattern\n",
    "        text_parts = example['text'].split('.')\n",
    "        if len(text_parts) > 1:\n",
    "            main_text = text_parts[0].strip()\n",
    "            rest_text = '.'.join(text_parts[1:]).strip()\n",
    "        else:\n",
    "            main_text = example['text']\n",
    "            rest_text = \"\"\n",
    "        \n",
    "        # Replace the pronoun with appropriate text\n",
    "        pronoun = example['pronoun'].lower()\n",
    "        if pronoun in [\"he\", \"she\", \"they\"]:\n",
    "            pronoun_text = f\"{pronoun} {verb}\"\n",
    "        elif pronoun in [\"him\", \"her\", \"them\"]:\n",
    "            pronoun_text = f\"{pronoun}self\"\n",
    "        else:\n",
    "            pronoun_text = pronoun\n",
    "        \n",
    "        # Generate domain-specific text\n",
    "        new_text = pattern.format(candidate=correct_candidate, rest=main_text)\n",
    "        if rest_text:\n",
    "            new_text += f\". {rest_text}\"\n",
    "        \n",
    "        # Find position of the pronoun in the new text\n",
    "        pronoun_pos = new_text.lower().find(pronoun.lower())\n",
    "        if pronoun_pos == -1:\n",
    "            # If we can't find the pronoun, use a default position\n",
    "            pronoun_pos = len(new_text) // 2\n",
    "        \n",
    "        # Create new example\n",
    "        new_example = example.copy()\n",
    "        new_example['text'] = new_text\n",
    "        new_example['pronoun_position'] = pronoun_pos\n",
    "        \n",
    "        domain_examples.append(new_example)\n",
    "    \n",
    "    return domain_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(original_data, augmentation_factor=2):\n",
    "    augmented_data = original_data.copy()\n",
    "    \n",
    "    # Track original example count\n",
    "    original_count = len(original_data)\n",
    "    target_count = original_count * augmentation_factor\n",
    "    \n",
    "    # Apply different augmentation techniques\n",
    "    while len(augmented_data) < target_count:\n",
    "        # Randomly select an original example to augment\n",
    "        example = random.choice(original_data)\n",
    "        \n",
    "        # Randomly select augmentation technique\n",
    "        technique = random.choice([\n",
    "            \"entity_swap\", \n",
    "            \"pronoun_variation\", \n",
    "            \"sentence_structure\", \n",
    "            \"add_distractors\",\n",
    "            \"cross_domain\"\n",
    "        ])\n",
    "        \n",
    "        # Apply selected technique\n",
    "        if technique == \"entity_swap\":\n",
    "            new_example = swap_entities(example)\n",
    "            augmented_data.append(new_example)\n",
    "        \n",
    "        elif technique == \"pronoun_variation\":\n",
    "            variations = vary_pronouns(example)\n",
    "            augmented_data.extend(variations)\n",
    "        \n",
    "        elif technique == \"sentence_structure\":\n",
    "            variations = modify_sentence_structure(example)\n",
    "            augmented_data.extend(variations)\n",
    "        \n",
    "        elif technique == \"add_distractors\":\n",
    "            new_example = add_distractors(example)\n",
    "            augmented_data.append(new_example)\n",
    "        \n",
    "        elif technique == \"cross_domain\":\n",
    "            domain = random.choice([\"news\", \"academic\", \"fiction\", \"conversation\"])\n",
    "            domain_examples = generate_cross_domain([example], domain)\n",
    "            augmented_data.extend(domain_examples)\n",
    "    \n",
    "    # Balance the dataset by pronoun type\n",
    "    augmented_data = balance_by_pronoun(augmented_data)\n",
    "    \n",
    "    # Shuffle the augmented dataset\n",
    "    random.shuffle(augmented_data)\n",
    "    \n",
    "    # Trim to target size\n",
    "    return augmented_data[:target_count]\n",
    "\n",
    "def balance_by_pronoun(examples):\n",
    "    \"\"\"Ensure balanced representation of different pronoun types.\"\"\"\n",
    "    pronoun_counts = {}\n",
    "    \n",
    "    # Count examples by pronoun type\n",
    "    for example in examples:\n",
    "        pronoun = example['pronoun'].lower()\n",
    "        if pronoun not in pronoun_counts:\n",
    "            pronoun_counts[pronoun] = []\n",
    "        pronoun_counts[pronoun].append(example)\n",
    "    \n",
    "    # Find the maximum number of examples per pronoun type\n",
    "    max_count = max(len(examples) for examples in pronoun_counts.values())\n",
    "    \n",
    "    # Balance the dataset\n",
    "    balanced_examples = []\n",
    "    for pronoun, pronoun_examples in pronoun_counts.items():\n",
    "        # If we have too few examples, duplicate some\n",
    "        if len(pronoun_examples) < max_count:\n",
    "            needed = max_count - len(pronoun_examples)\n",
    "            additional = random.choices(pronoun_examples, k=needed)\n",
    "            pronoun_examples.extend(additional)\n",
    "        \n",
    "        # Take max_count examples for this pronoun\n",
    "        balanced_examples.extend(pronoun_examples[:max_count])\n",
    "    \n",
    "    return balanced_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 1200 examples\n",
      "Augmented dataset: 3600 examples\n"
     ]
    }
   ],
   "source": [
    "# Load your original data\n",
    "import json\n",
    "\n",
    "def load_data(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # validation\n",
    "    for item in data:\n",
    "        assert 'text' in item, \"Missing 'text' field\"\n",
    "        assert 'pronoun' in item, \"Missing 'pronoun' field\"\n",
    "        assert 'candidates' in item, \"Missing 'candidates' field\"\n",
    "        assert 'pronoun_position' in item, \"Missing 'pronoun_position' field\"\n",
    "        assert 'correct_candidate_idx' in item, \"Missing 'correct_candidate_idx' field\"\n",
    "    \n",
    "    random.shuffle(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "original_data = load_data(\"pronoun__dataset.json\")\n",
    "\n",
    "# Apply augmentation (5x increase in dataset size)\n",
    "augmented_data = augment_dataset(original_data, augmentation_factor=3)\n",
    "\n",
    "# Save augmented dataset\n",
    "with open(\"augmented_pronoun_resolution_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(augmented_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Original dataset: {len(original_data)} examples\")\n",
    "print(f\"Augmented dataset: {len(augmented_data)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
