{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "class TopicClassifier:\n",
    "    def __init__(self, model_type='naive_bayes'):\n",
    "        self.model_type = model_type\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.pipeline = None\n",
    "        self.classes = ['news', 'cooking', 'football']\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens if word not in self.stop_words]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        # Ensure the dataframe has 'text' and 'label' columns\n",
    "        if 'text' not in df.columns or 'label' not in df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'text' and 'label' columns\")\n",
    "        \n",
    "        # Check that all labels are in the expected classes\n",
    "        if not all(label in self.classes for label in df['label'].unique()):\n",
    "            raise ValueError(f\"All labels must be one of: {self.classes}\")\n",
    "        \n",
    "        # Apply preprocessing to text\n",
    "        df['processed_text'] = df['text'].apply(self.preprocess_text)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def build_pipeline(self):\n",
    "        # TF-IDF vectorizer\n",
    "        tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "        \n",
    "        # Select classifier based on model_type\n",
    "        if self.model_type == 'naive_bayes':\n",
    "            classifier = MultinomialNB()\n",
    "        elif self.model_type == 'logistic_regression':\n",
    "            classifier = LogisticRegression(max_iter=1000, C=1.0)\n",
    "        elif self.model_type == 'svm':\n",
    "            classifier = LinearSVC(C=1.0)\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be one of: 'naive_bayes', 'logistic_regression', 'svm'\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        self.pipeline = Pipeline([\n",
    "            ('tfidf', tfidf),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "    \n",
    "    def train(self, df, test_size=0.2, random_state=42):\n",
    "        # Prepare data\n",
    "        df = self.prepare_data(df)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df['processed_text'], \n",
    "            df['label'], \n",
    "            test_size=test_size, \n",
    "            random_state=random_state,\n",
    "            stratify=df['label']\n",
    "        )\n",
    "        \n",
    "        # Build and train pipeline\n",
    "        self.build_pipeline()\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        predictions = self.pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        report = classification_report(y_test, predictions)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'report': report,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "    \n",
    "    def predict(self, query):\n",
    "        \"\"\"Predict the class of a user query\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Model has not been trained yet. Call train() first.\")\n",
    "        \n",
    "        # Preprocess the query\n",
    "        processed_query = self.preprocess_text(query)\n",
    "        \n",
    "        # Make prediction\n",
    "        predicted_class = self.pipeline.predict([processed_query])[0]\n",
    "        \n",
    "        # Get probabilities if available\n",
    "        if hasattr(self.pipeline, 'predict_proba'):\n",
    "            probabilities = self.pipeline.predict_proba([processed_query])[0]\n",
    "            proba_dict = {self.classes[i]: probabilities[i] for i in range(len(self.classes))}\n",
    "            return {'class': predicted_class, 'probabilities': proba_dict}\n",
    "        \n",
    "        return {'class': predicted_class}\n",
    "\n",
    "# Example usage:\n",
    "def example_usage():\n",
    "    # Sample data (replace with your actual labeled dataset)\n",
    "    data = {\n",
    "        'text': [\n",
    "            \"Latest updates on the presidential election\",\n",
    "            \"Breaking news: Stock market hits record high\",\n",
    "            \"How to make a perfect spaghetti carbonara\",\n",
    "            \"Best chocolate chip cookie recipe\",\n",
    "            \"Manchester United wins against Chelsea\",\n",
    "            \"NFL draft picks for the upcoming season\",\n",
    "            \"Government announces new economic policy\",\n",
    "            \"5 ways to prepare quick breakfast\",\n",
    "            \"Champions League final match results\"\n",
    "        ],\n",
    "        'label': [\n",
    "            \"news\", \"news\", \"cooking\", \"cooking\", \"football\", \n",
    "            \"football\", \"news\", \"cooking\", \"football\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Initialize and train the classifier\n",
    "    classifier = TopicClassifier(model_type='naive_bayes')\n",
    "    results = classifier.train(df)\n",
    "    \n",
    "    print(f\"Model Accuracy: {results['accuracy']:.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(results['report'])\n",
    "    \n",
    "    # Test with a new query\n",
    "    test_queries = [\n",
    "        \"What's the latest on the coronavirus vaccine?\",\n",
    "        \"How do I bake a chocolate cake?\",\n",
    "        \"When is the next World Cup match?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nPredictions for test queries:\")\n",
    "    for query in test_queries:\n",
    "        prediction = classifier.predict(query)\n",
    "        print(f\"Query: '{query}'\")\n",
    "        print(f\"Predicted class: {prediction['class']}\")\n",
    "        if 'probabilities' in prediction:\n",
    "            print(\"Class probabilities:\")\n",
    "            for cls, prob in prediction['probabilities'].items():\n",
    "                print(f\"  {cls}: {prob:.2f}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()\n",
    "\n",
    "\n",
    "def load_and_train_with_real_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Initialize classifier with preferred model\n",
    "    # Options: 'naive_bayes', 'logistic_regression', 'svm'\n",
    "    classifier = TopicClassifier(model_type='logistic_regression')\n",
    "    \n",
    "    # Train model\n",
    "    results = classifier.train(df)\n",
    "    \n",
    "    print(f\"Model Accuracy: {results['accuracy']:.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(results['report'])\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "# Function to classify user queries in your application\n",
    "def classify_user_query(classifier, query):\n",
    "    result = classifier.predict(query)\n",
    "    return result['class']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
